/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 04.04.2023 11:31:58

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 2672;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[23];
TfLiteEvalTensor tflEvalTensors[23];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[11];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,637 } };
const TfArray<1, float> quant0_scale = { 1, { 0.046899929642677307, } };
const TfArray<1, int> quant0_zero = { 1, { -9 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 49, 13, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 49, 1, 16, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 25, 16, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 25, 1, 32, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data5[2] = { -1, 416, };
const TfArray<1, int> tensor_dimension5 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data6[16*1*3*13] = { 
  /* [0][0][][] */ -30,-127,19,66,117,-2,-84,-48,-20,-4,19,-17,-8, -98,-98,-69,-32,124,-31,13,79,30,-26,20,49,83, -70,-65,-57,-34,6,22,-39,-72,-9,-57,63,-36,-58, 
  /* [1][0][][] */ -73,-15,-36,-56,-24,55,-10,-36,2,66,-31,-88,-11, -68,-57,-59,-90,-55,45,30,-20,-12,-50,-7,31,-2, -90,-50,-22,-44,94,85,127,-10,3,-19,-3,-1,-2, 
  /* [2][0][][] */ -49,-18,-9,-40,-39,18,-11,35,-6,25,-7,10,-15, 31,32,-56,65,-60,-6,0,-7,-5,-11,-34,18,-12, 122,127,50,-27,-62,-14,30,-13,-28,24,15,-19,11, 
  /* [3][0][][] */ -91,-31,63,82,118,27,-49,48,75,-62,25,24,65, -59,-126,-103,-36,45,-52,-7,0,12,118,-3,-52,-127, -99,-33,-25,-69,49,65,-25,-2,-67,0,-63,19,52, 
  /* [4][0][][] */ 8,-86,32,-8,-18,26,9,24,6,12,3,1,-3, 47,-48,-2,5,-2,5,-27,19,-3,5,-31,-2,-31, 18,-127,-10,6,31,-13,-9,2,6,-3,-20,10,-11, 
  /* [5][0][][] */ 20,-70,74,5,127,43,70,-80,-10,-75,12,50,50, 89,-13,113,76,102,18,-3,-70,-126,-90,-35,5,9, -37,49,-10,92,-59,-61,-60,-44,-45,-25,15,18,-23, 
  /* [6][0][][] */ -68,-124,-43,91,30,9,-20,43,84,-16,2,43,-78, -127,-51,-107,-31,52,43,-10,-80,-55,25,-44,-23,49, -57,-111,-54,-110,67,28,-66,-57,22,-14,-31,-6,6, 
  /* [7][0][][] */ -116,-49,63,19,83,-15,10,-32,-64,-29,33,29,-8, -127,34,-48,44,78,83,-26,13,36,-108,65,41,19, -102,24,35,24,25,73,77,77,65,-58,47,-38,-50, 
  /* [8][0][][] */ 79,-5,-53,-11,44,57,9,-37,0,-9,-6,-12,-9, 35,-33,-55,-21,96,-45,-85,18,21,32,-36,-38,-61, -9,48,-87,-25,49,4,-127,-51,48,24,-14,-94,31, 
  /* [9][0][][] */ -30,-16,28,-67,-59,-66,49,61,34,-60,3,-60,23, -33,89,14,31,-37,14,20,26,5,127,-65,-2,47, -74,-96,42,53,3,19,-1,-10,87,76,-45,56,20, 
  /* [10][0][][] */ -106,100,-102,76,14,51,-11,-45,9,9,5,38,-63, -127,7,21,-1,53,7,-32,-17,48,10,13,-31,-14, -99,21,57,45,12,30,-32,34,23,-6,-8,-53,-28, 
  /* [11][0][][] */ 69,125,-94,39,63,47,71,-78,36,15,74,-23,-14, -56,44,11,15,39,21,-28,-26,-42,25,16,19,-11, -127,69,106,-11,57,-79,11,-6,35,-89,36,0,35, 
  /* [12][0][][] */ 87,92,-114,-2,-1,-4,58,-63,-19,-9,-27,9,-4, -73,-32,-53,0,17,127,4,7,-100,-73,-82,39,-86, -37,-49,-66,76,70,53,34,-15,-72,45,31,83,-51, 
  /* [13][0][][] */ 58,2,-16,-46,55,12,-39,3,-9,63,116,58,-95, 11,4,-38,-55,127,39,18,-40,11,90,98,33,-125, -27,-48,-53,-70,3,27,-17,-7,25,44,80,20,27, 
  /* [14][0][][] */ -32,-80,9,62,104,48,-42,38,41,3,21,29,-45, 2,6,19,114,54,-30,-14,-11,-20,-32,-52,-28,-7, -6,127,31,79,62,8,-45,-15,-11,-12,-13,14,13, 
  /* [15][0][][] */ -105,21,-42,22,-11,17,38,5,-26,-26,24,11,-10, -127,18,-31,-61,-44,-10,15,-8,15,1,18,-30,-33, -73,-38,25,-30,-72,-10,44,21,25,1,23,-33,62, 
};
const TfArray<4, int> tensor_dimension6 = { 4, { 16,1,3,13 } };
const TfArray<16, float> quant6_scale = { 16, { 0.0034866451751440763, 0.0035812435671687126, 0.0038351791445165873, 0.0028880443423986435, 0.0070579475723206997, 0.0028976148460060358, 0.0033696645405143499, 0.0032500328961759806, 0.0040205004625022411, 0.0030935031827539206, 0.0042804060503840446, 0.0035318457521498203, 0.0028288022149354219, 0.0031011737883090973, 0.00426093814894557, 0.0052732909098267555, } };
const TfArray<16, int> quant6_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int32_t tensor_data7[16] = { -916, -235, -2613, 1641, -252, -3385, 579, -662, -2765, -1146, -1462, -1524, -1472, -2670, -1972, 410, };
const TfArray<1, int> tensor_dimension7 = { 1, { 16 } };
const TfArray<16, float> quant7_scale = { 16, { 0.00016352340753655881, 0.00016796006821095943, 0.0001798696321202442, 0.00013544908142648637, 0.0003310172469355166, 0.00013589793525170535, 0.00015803702990524471, 0.00015242632071021944, 0.00018856118549592793, 0.00014508508320432156, 0.00020075074280612171, 0.00016564331599511206, 0.00013267062604427338, 0.00014544483565259725, 0.00019983769743703306, 0.000247316958848387, } };
const TfArray<16, int> quant7_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int8_t tensor_data8[32*1*3*16] = { 
  /* [0][0][][] */ -21,-41,-74,-10,22,-17,-11,-25,9,75,-24,-13,42,12,0,-79, 9,29,-89,-19,1,-16,33,-21,5,-51,-22,-54,18,2,16,-78, -6,-31,-127,7,14,-21,9,-27,15,-19,-24,-51,46,27,-7,-92, 
  /* [1][0][][] */ -93,-18,-7,-93,-48,-53,-127,-16,10,23,9,-19,-1,-20,10,-13, -95,12,-21,-100,-63,51,-83,13,99,-8,-17,14,-7,23,39,-34, -46,-19,-24,-24,-58,24,-52,67,30,-23,50,51,0,43,-13,-12, 
  /* [2][0][][] */ -7,-127,-76,-16,30,-46,51,-89,32,-37,9,-42,-62,50,12,-11, 66,-108,-50,-10,26,-28,22,-124,68,2,15,-30,-73,-49,54,-113, 17,-24,-83,5,-17,-39,41,-28,94,-41,33,-37,52,-26,47,13, 
  /* [3][0][][] */ -122,-13,10,-78,-46,-98,-56,-49,-3,26,-101,94,16,-9,-49,0, -79,78,-47,-18,6,-73,-12,-13,-70,40,-84,-70,-43,54,-58,62, 15,40,-127,45,83,-50,22,-23,-45,-9,-43,-110,-13,-4,-5,-26, 
  /* [4][0][][] */ 46,96,37,-22,-24,-72,0,45,-13,48,-29,-84,-32,-49,-101,28, -89,5,-14,-119,-56,-33,-109,-58,-12,6,-89,-71,57,-58,-122,-5, -55,-20,20,-103,-10,33,-52,15,-19,3,84,31,24,-48,-8,-127, 
  /* [5][0][][] */ 57,-61,8,-21,-5,-104,9,-36,-15,21,-3,-83,-62,0,-48,22, 4,-20,-15,-26,-45,-80,-33,17,-44,6,-63,-127,-82,-31,-16,7, -41,32,30,-11,-33,9,-11,-47,-14,-1,-56,-53,20,-52,-50,-41, 
  /* [6][0][][] */ -72,22,-13,-127,-63,-16,-92,-31,-43,29,29,-15,37,-29,-71,-7, -37,-29,-29,-8,-70,-23,-48,-31,29,-40,25,-14,22,2,-45,-60, -10,-51,-34,-16,-79,26,3,42,16,-75,50,39,4,43,36,-70, 
  /* [7][0][][] */ -65,85,-127,36,1,-126,50,-13,-77,-33,36,-63,16,-43,16,42, -63,91,-114,9,27,-78,33,15,-5,32,37,-101,-61,-27,-64,3, -42,22,-114,-34,-56,107,-30,16,-6,-102,65,-46,57,-121,51,-20, 
  /* [8][0][][] */ -56,21,-10,-52,-53,-19,-20,35,40,8,-36,127,-40,-64,62,41, -21,11,5,-62,-62,48,-70,59,37,-44,-108,18,-31,-41,-89,0, -29,-35,-41,0,-48,-6,-82,1,-27,24,-83,-28,46,65,-97,115, 
  /* [9][0][][] */ -24,-6,126,-91,-25,-4,8,36,-90,26,-36,-47,-71,-12,-15,-34, -27,-14,-37,-24,-44,-2,7,-72,-82,-29,-64,26,-110,-76,-15,-30, 43,-127,-57,-83,10,32,-40,-20,-33,-41,-5,-2,95,-52,-69,-86, 
  /* [10][0][][] */ 3,-13,1,-70,127,52,-26,21,40,-4,-14,20,12,26,-44,-69, 17,-17,2,-103,-89,44,-82,-64,24,-19,-48,10,25,18,-37,-11, -14,12,-1,-98,-69,-2,-98,-15,93,-11,21,55,-32,26,66,21, 
  /* [11][0][][] */ -37,-47,-58,25,-48,127,-48,18,-3,-63,73,75,-20,-51,24,30, -89,15,-39,20,42,-51,-12,2,-65,-34,36,14,-26,-1,-52,-12, -59,13,-7,-10,74,-75,-39,-94,-8,38,-61,-45,-34,26,-68,48, 
  /* [12][0][][] */ -17,-77,11,-8,35,92,-16,-7,5,-34,25,1,-48,-5,55,-29, -41,-61,9,-95,77,-14,-74,-78,2,-27,-27,19,-20,16,-4,-52, -99,-43,12,-127,37,-6,-106,-87,42,-14,-55,13,9,1,-3,1, 
  /* [13][0][][] */ -123,-102,-31,-124,-101,5,-127,-42,-47,5,18,42,62,10,-23,-7, -80,-47,-63,-49,-12,51,-98,57,-36,-69,10,54,19,-1,36,14, -88,-47,-53,-5,-56,18,-19,18,-100,-7,73,2,-16,-26,56,-55, 
  /* [14][0][][] */ -16,-27,-40,3,45,-18,36,0,-36,68,-18,-25,-95,42,26,-42, 11,-46,-51,40,37,-4,-26,-26,22,-69,-38,-16,-28,99,41,-104, -8,-35,15,-47,28,57,-7,-70,42,-85,-44,-50,20,-30,-5,-127, 
  /* [15][0][][] */ 14,-17,-97,13,42,-24,35,21,53,-18,-23,-104,27,-49,-32,30, 15,-11,-34,11,-21,-43,-4,11,-101,-30,-45,-113,-24,-27,-51,-38, -2,-17,-25,12,127,31,4,-14,-108,-20,-80,-86,24,-66,-112,-55, 
  /* [16][0][][] */ -127,107,-6,-59,-12,-103,-77,-50,-116,38,25,3,8,71,-101,73, -90,19,-53,-78,-16,-47,-38,60,-49,12,-21,23,-29,5,-83,10, -65,28,-59,48,6,-13,-55,8,-104,-16,38,21,-51,-16,-104,71, 
  /* [17][0][][] */ 82,-4,-34,7,-30,-25,0,-93,44,13,-127,-93,-34,30,-38,-28, 40,71,-56,-70,-29,-52,-32,37,1,62,-57,-107,62,-50,-39,-44, 64,11,-88,30,45,-66,100,-61,72,-26,-51,-80,54,-51,-48,-65, 
  /* [18][0][][] */ -74,-41,-39,-82,-66,18,-91,0,-54,-67,60,13,101,95,28,-111, -65,-104,-53,-36,-44,23,-59,51,115,-45,81,-32,-17,67,10,-36, -9,-104,-84,-10,-121,-35,-46,14,-9,127,-2,-79,-67,-2,77,-9, 
  /* [19][0][][] */ 12,-28,20,0,-1,-35,33,-14,-3,-52,46,-10,-101,0,-14,127, 20,-23,17,-34,-66,-15,-51,-15,-14,36,-27,-58,-22,-16,-24,-54, -46,-125,59,-43,-90,24,-127,-98,-49,-8,-37,-20,-21,-54,-42,25, 
  /* [20][0][][] */ 13,-1,-46,-7,-34,-11,-25,55,-79,48,59,31,-4,-26,22,-117, -42,-60,14,26,-59,12,-9,-58,-17,-74,-32,-6,-42,42,3,-43, 28,-36,4,-33,-26,-66,-17,-81,89,-118,-29,-68,14,98,-127,53, 
  /* [21][0][][] */ 6,-24,105,43,-62,-87,10,-74,-97,15,44,47,17,-110,-25,53, 5,-105,-113,-78,-16,-63,-45,54,-127,75,4,-6,92,-109,-19,28, -18,-36,107,37,49,-59,-113,-126,-33,47,-88,-53,27,-50,-6,-22, 
  /* [22][0][][] */ -23,62,-9,30,-43,-87,55,-63,-19,-127,41,-26,49,-106,54,-76, -30,55,56,-76,-71,-89,17,-64,-58,-23,-2,13,96,-118,59,109, 12,69,32,54,-34,-76,-80,48,-89,-68,72,-38,-92,-81,-26,-38, 
  /* [23][0][][] */ -4,-51,-10,-20,8,39,-13,-5,-20,-31,22,17,-35,-4,86,-61, -45,-25,7,-72,-70,46,-61,-71,36,-38,-38,9,0,57,-13,-4, -69,10,14,-83,-75,-33,-127,-101,-27,-7,-60,29,32,31,-49,3, 
  /* [24][0][][] */ 3,4,-25,38,-21,10,24,59,-71,-11,-10,-16,-49,-42,2,60, -50,1,33,3,12,-24,-30,-19,-30,31,-127,-33,30,-46,-56,12, -69,-81,22,-107,-32,-35,-87,-20,-61,2,-109,-3,12,-68,-36,0, 
  /* [25][0][][] */ -50,-70,29,-70,32,-14,-30,-42,-19,-61,-70,30,13,37,-53,-76, 6,-42,88,2,18,-41,44,-42,-34,-81,0,49,-26,-27,-69,64, -27,-105,1,-31,73,-41,20,-127,24,-54,-121,19,80,34,-38,-11, 
  /* [26][0][][] */ 11,19,-127,16,29,-43,6,4,-71,-49,-19,-53,14,6,-64,21, -39,26,-49,-16,54,-37,-34,31,-36,13,-16,-19,-39,-31,26,-39, -32,-45,16,-67,-42,45,-42,-29,39,-38,-7,3,-32,-4,57,-5, 
  /* [27][0][][] */ -78,45,-36,-39,16,-63,-48,-15,-20,73,-98,26,42,10,-31,16, -54,-39,-107,-52,-19,-76,11,-63,-37,62,-47,-117,-29,6,-65,17, 16,38,-127,28,42,-48,14,-25,20,-49,-52,-124,47,30,-10,30, 
  /* [28][0][][] */ -71,-103,-48,-40,-53,-29,-54,-17,13,-20,84,21,-13,22,17,16, -11,-127,-24,1,-13,-21,-12,1,-7,9,1,40,-53,-17,-7,-58, 44,-50,-82,12,19,-30,20,5,-14,3,80,-37,-39,7,44,-32, 
  /* [29][0][][] */ 9,14,-66,2,-2,-46,-13,29,-47,54,54,-70,-126,-58,-22,71, 37,-10,86,19,-22,-45,-82,-37,-72,-16,-81,-73,-44,-100,-53,6, -46,-40,29,-69,-62,22,-114,-57,-92,29,-127,-47,35,-123,-36,-2, 
  /* [30][0][][] */ -56,-13,-10,-127,-7,-2,-78,-35,74,12,68,18,12,4,-56,38, -10,-51,-17,-30,29,35,-89,-30,36,21,-64,6,-13,-1,-64,43, -33,-52,-13,-39,-43,30,-56,17,-56,3,64,22,19,-1,60,-41, 
  /* [31][0][][] */ 4,16,-127,-20,-7,-43,34,-5,-62,-46,56,-12,-8,-96,21,-27, 34,-28,66,9,-66,-21,11,4,-53,-15,13,8,32,-78,-9,-18, -16,-21,45,10,-94,-45,-17,60,-24,10,20,-4,-3,-66,-21,11, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 32,1,3,16 } };
const TfArray<32, float> quant8_scale = { 32, { 0.0052921040914952755, 0.0048076445236802101, 0.0029690675437450409, 0.0036408733576536179, 0.0037979590706527233, 0.0044584036804735661, 0.0053957565687596798, 0.0024184519425034523, 0.0028905072249472141, 0.0026888533029705286, 0.0037850302178412676, 0.0034071323461830616, 0.0050380127504467964, 0.0036982439924031496, 0.0037021161988377571, 0.0035196647513657808, 0.0026757426094263792, 0.0028802950400859118, 0.0025416472926735878, 0.0033088342752307653, 0.0029427958652377129, 0.0021562038455158472, 0.0021327708382159472, 0.0053765471093356609, 0.0053386799991130829, 0.0032642006408423185, 0.0048493999056518078, 0.0034431838430464268, 0.0043026464991271496, 0.0032107261940836906, 0.0047599505633115768, 0.0036809449084103107, } };
const TfArray<32, int> quant8_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int32_t tensor_data9[32] = { 1026, -1341, -211, 290, -106, 537, -917, -1030, -305, -333, -1603, -231, -656, -1010, -194, -1053, 458, -460, -1391, -1078, -1398, -913, -2279, -1218, -497, -822, -433, 673, -1351, -735, -392, -720, };
const TfArray<1, int> tensor_dimension9 = { 1, { 32 } };
const TfArray<32, float> quant9_scale = { 32, { 0.00020970619516447186, 0.00019050887203775346, 0.00011765298404498026, 0.00014427411952055991, 0.00015049884677864611, 0.00017666978237684816, 0.00021381354599725455, 9.5834162493702024e-05, 0.00011453993647592142, 0.00010654914512997493, 0.000149986517499201, 0.00013501184002961963, 0.00019963750673923641, 0.00014654750702902675, 0.00014670094242319465, 0.00013947108527645469, 0.00010602961992844939, 0.00011413526226533577, 0.00010071592987515032, 0.00013111667067278177, 0.00011661194002954289, 8.5442254203371704e-05, 8.4513689216692001e-05, 0.00021305234986357391, 0.00021155181457288563, 0.0001293480017920956, 0.00019216348300687969, 0.00013644043065141886, 0.00017049770394805819, 0.00012722901010420173, 0.00018861894204746932, 0.00014586200995836407, } };
const TfArray<32, int> quant9_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int8_t tensor_data10[3*416] = { 
  -23, 6, -31, 31, -127, -49, -11, 16, -28, -21, -17, 39, 16, 6, -31, -34, -5, 44, -16, -16, -14, -23, 9, 27, -77, -59, 38, 13, -15, -95, -12, 0, -11, 19, 14, -7, -89, 7, -32, 11, 30, -21, 2, 27, 54, -14, 12, 34, 17, -4, -3, -11, -3, -17, 16, 40, -45, -17, 39, -7, -65, -53, -7, 17, 9, 47, -4, -19, -13, -26, -32, 23, 3, -48, 41, -9, 71, -18, 8, 39, 2, -4, 40, -28, 29, -48, -6, 73, -49, -11, 38, 14, -19, -63, 29, -18, -11, 38, 0, 17, -63, -46, 0, 13, 44, -46, 25, 43, 80, -26, 19, 32, 12, 12, 1, -57, 63, -25, 19, 73, -106, 11, 50, -7, 8, -73, 36, -15, -62, 6, 0, 22, -49, -26, -12, 15, -6, -24, 29, 5, 75, -16, 11, 9, 16, -16, -18, -10, 40, -32, 2, 64, -26, 30, 23, -8, -18, -63, -22, -1, -27, 42, 23, -23, -47, -46, 18, 0, 18, -11, 39, 34, 86, 7, 50, 23, 14, -30, -11, -52, 17, -11, -11, 67, -90, -7, 62, -43, 10, -75, 14, 17, -19, 11, 10, 23, -49, -57, 12, 39, -1, -55, 45, 28, 43, -22, 15, 27, 21, -48, 29, -6, -6, -11, 3, 45, -21, 25, 60, -9, 16, -40, 29, -22, -45, 13, 27, 25, -25, -57, -2, 39, 31, -39, 5, 81, 66, -22, 2, 29, 21, 16, 1, -47, 22, -3, -25, 9, -25, -7, 13, -20, -17, -59, 17, 10, -22, 28, -27, -8, -20, -2, 5, 11, 38, -41, 31, 54, 75, 14, 10, 51, 16, -30, 12, -39, 3, -6, -14, 56, -43, -22, 16, -41, 24, -74, 17, -28, -5, 5, -28, -20, -3, -23, 10, 6, -27, -37, 28, 32, 30, -12, 23, -2, 6, -10, -8, -15, -19, -9, 9, 55, -82, 16, 49, -2, -16, -35, 3, -10, 6, 44, -42, -10, -52, -9, -21, -38, 48, -40, 13, 7, 64, 9, 12, -23, 6, -63, 8, -14, 27, -27, -7, 62, -46, -37, 20, -12, -11, -59, 15, 10, -16, 15, -19, 10, -24, -11, -25, -28, 40, -21, 25, 13, -9, -6, -27, 10, 49, -2, -18, -26, -30, -37, -30, 22, -26, -44, 43, -7, -22, -15, 23, 21, 0, 9, -4, 39, -8, -39, 28, -21, 24, -43, 9, -17, 12, 46, -42, -18, 71, -16, -10, 3, -46, -29, -5, 8, 17, 23, -17, 23, -43, 12, 22, -25, 
  -5, -25, 20, 1, 53, -25, -9, 27, 13, 11, -9, -46, 10, -40, -4, -2, -29, 17, 16, 9, 7, 15, 13, 32, 8, 76, -31, -6, 30, 27, -28, -3, 18, -6, 11, 10, 30, 8, -19, 14, 0, 16, 14, -23, -47, -47, -9, -13, -5, -32, 12, 13, -27, 18, 5, -65, 20, 39, -53, -31, 37, 17, 4, 14, -1, -17, 16, 31, 10, 29, -23, -22, -11, 15, -25, -24, 1, -21, -31, -43, 28, -17, -5, 10, -6, 12, 16, -10, 33, 3, -10, 21, 57, 40, 16, 14, -5, -66, 31, 56, 11, -14, -46, 33, -4, 39, -59, -29, -8, -56, -5, 10, -32, -8, -47, 40, -16, 24, 10, 10, 16, 23, -25, 49, 1, 26, -74, 22, 54, -12, -24, 38, 22, 1, -63, 36, 24, 10, -5, -31, 24, -63, -44, 3, -38, 29, -16, 27, -58, 37, 25, 0, 57, 21, -3, 59, -23, 39, -46, 35, 42, -68, 22, 35, -1, 3, -40, -1, -4, 34, -65, -33, 23, -87, 40, -33, -17, 3, -51, 9, 17, 24, 9, -14, 40, 17, -48, 57, -41, 27, -82, 24, 52, -34, 22, 32, -11, 10, -57, 6, -7, -7, -58, -20, -15, -52, 11, 16, -4, 41, -48, 28, -34, 13, 35, -20, 17, -16, 30, 13, -74, 4, -33, -1, 62, -91, 23, 45, 19, 10, -110, 45, -14, 10, -11, -24, -8, -49, -1, -24, -12, 14, -34, 18, 8, 20, 17, 9, 2, 12, 16, 6, -10, 48, -27, 19, 47, -30, 56, 53, -14, 2, -69, 12, -11, 8, -18, -20, -21, -35, 6, -18, 10, 23, -56, 13, 5, -27, 22, -31, 25, -23, -16, 9, -23, 35, -68, 1, 75, -54, 31, 39, 2, -15, -69, 14, -20, -4, -66, -39, -35, -32, 48, 3, -2, -6, -22, 23, 37, 19, -4, -24, 59, 17, -28, 16, -16, -13, -55, 21, 5, -44, -13, 36, -12, -10, -42, -1, -47, 15, -22, -59, -20, -44, 8, -43, -36, 28, 5, 15, -17, 27, 28, -54, -18, 68, 14, 23, 23, -27, -53, 34, 35, -31, 22, 47, -7, -8, 4, -9, -9, -21, 13, 4, -13, -38, 14, -8, -11, 23, 23, -14, 4, 28, -14, -61, -1, 22, -19, 6, 9, 20, 3, 14, 27, -62, 20, 20, -17, -18, -12, -18, -3, 5, -7, 42, -17, -69, 27, -24, 35, -35, 44, 9, 25, -3, 28, -16, 26, -16, 15, -11, -10, 13, 19, 5, 
  6, -6, 12, -9, 58, 69, 25, -30, 15, -2, -1, -5, -14, 34, 45, 20, -30, 7, 2, 2, 40, 16, -34, -88, 24, -4, -41, -4, 2, 34, 40, 9, -6, 38, 19, -26, 37, 19, 31, -11, -53, -22, 1, -7, -52, 24, -28, 19, -48, 0, -19, 4, -15, -23, -8, 19, -5, -1, -10, -24, 8, -7, 15, -17, 22, 30, -12, -26, 20, 28, 63, 1, -26, 17, -7, 7, -70, -2, -28, 29, -19, 43, -11, -7, 7, 4, -6, -40, 8, -6, 2, -12, -12, 15, -6, -2, -3, 29, 6, -68, 46, 56, 58, -10, -23, 4, -20, 5, -46, 95, -47, 13, -45, 11, 14, 8, -21, 15, -11, -77, 15, -8, -57, -36, -1, 29, 42, -30, -4, 8, 9, -60, 22, 45, 34, -9, -6, 10, 21, 15, -70, 35, -5, 7, -24, -4, 10, 0, 19, -15, -11, -46, 25, -27, -37, -24, 26, 6, 33, 8, -48, 41, -20, -33, -11, 57, 50, -15, 1, -23, 21, 27, -59, 54, -26, 7, -2, -32, 34, 34, -13, 6, -30, -89, 7, -8, -41, -36, 43, 18, 36, -42, -20, 27, -55, -91, 25, 31, 69, -7, -14, 48, 18, -17, -54, 36, -20, -41, -35, 0, 31, 10, -18, -10, 2, -44, -5, -17, -65, -47, 44, 6, 13, 0, -28, 22, -41, -63, 12, 30, 75, -25, -40, -8, 21, 1, -69, 37, -29, 2, -5, -22, 25, 31, 9, 6, -25, -64, 8, 6, -23, -16, 20, 14, 3, 3, -27, 29, -3, -28, 2, 59, 48, -7, 36, 33, 36, 19, -37, 18, -48, -32, -21, 24, 12, 21, 27, -3, -20, -33, 5, 20, 30, -18, 15, 35, 35, -6, -59, 17, 19, -70, 21, 38, 34, -52, 6, -6, 20, 14, -24, 7, -53, -1, -32, 32, 34, 29, 20, -7, 11, -20, -5, 14, -24, -73, 10, 19, 38, -3, -36, 49, 3, -37, 6, 19, 45, -12, 26, 3, 12, -5, -53, 22, -38, 34, 1, 20, 14, 10, -9, 4, 1, -14, 29, -18, -16, -15, 14, 27, 49, -15, -25, 15, 8, -62, 40, 40, 49, -27, -25, 9, 8, 26, -54, 1, -14, 6, -8, 32, 1, 26, 19, -17, 9, 21, 3, -5, 19, -23, 21, 17, 6, -12, -41, 53, 19, 4, -24, 29, 13, 10, 0, 35, 25, 13, -26, 26, 27, 36, -55, 51, 23, 28, 17, 31, 39, 1, -52, -7, -14, -45, 38, -10, -28, 0, 
};
const TfArray<2, int> tensor_dimension10 = { 2, { 3,416 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0043688439764082432, } };
const TfArray<1, int> quant10_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(8) int32_t tensor_data11[3] = { -564, 2002, -1487, };
const TfArray<1, int> tensor_dimension11 = { 1, { 3 } };
const TfArray<1, float> quant11_scale = { 1, { 0.0001138543157139793, } };
const TfArray<1, int> quant11_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,49,13 } };
const TfArray<1, float> quant12_scale = { 1, { 0.046899929642677307, } };
const TfArray<1, int> quant12_zero = { 1, { -9 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,49,16 } };
const TfArray<1, float> quant13_scale = { 1, { 0.039626240730285645, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,49,1,16 } };
const TfArray<1, float> quant14_scale = { 1, { 0.039626240730285645, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,25,1,16 } };
const TfArray<1, float> quant15_scale = { 1, { 0.039626240730285645, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,25,16 } };
const TfArray<1, float> quant16_scale = { 1, { 0.039626240730285645, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,25,32 } };
const TfArray<1, float> quant17_scale = { 1, { 0.026060512289404869, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,25,1,32 } };
const TfArray<1, float> quant18_scale = { 1, { 0.026060512289404869, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,13,1,32 } };
const TfArray<1, float> quant19_scale = { 1, { 0.026060512289404869, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,416 } };
const TfArray<1, float> quant20_scale = { 1, { 0.026060512289404869, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,3 } };
const TfArray<1, float> quant21_scale = { 1, { 0.07706153392791748, } };
const TfArray<1, int> quant21_zero = { 1, { -6 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,3 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 12,6,7 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 13,2 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 15,3 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 16,8,9 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 17,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,5 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,10,11 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 640, (TfLiteIntArray*)&tensor_dimension0, 637, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 624, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 1536, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 128, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 1248, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 12, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 637, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 784, (TfLiteIntArray*)&tensor_dimension13, 784, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 784, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 784, (TfLiteIntArray*)&tensor_dimension15, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 800, (TfLiteIntArray*)&tensor_dimension17, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 800, (TfLiteIntArray*)&tensor_dimension19, 416, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension20, 416, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 416, (TfLiteIntArray*)&tensor_dimension21, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension22, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant22))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs10, (TfLiteIntArray*)&outputs10, const_cast<void*>(static_cast<const void*>(&opdata10)), OP_SOFTMAX, },
};
static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else {
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 11; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 11; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  22, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
